{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis :  Gender disparities in police stops accross the United States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed \n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import collections \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling\n",
    "- Datasets choice and loading\n",
    "- Filtering of incomplete rows and unnecessary features\n",
    "- Formatting\n",
    "\n",
    "The datasets handled are : \n",
    "- Set 1 : NC (Charlotte, Greensboro, Raleigh), Austin (TX), CA (San Diego), Maryland state (MD)\n",
    "- Set 2 : NC (Charlotte, Greensboro, Raleigh), CA (San Diego and San Francisco), Nashville (TN), New Orleans (Louisiana), Maryland state (MD)\n",
    "- Case study : Florida state (FL)\n",
    "\n",
    "Also available : Washington state (WA) with officers' gender, Louisville (Kentucky), and Pittsburgh (Philadelphia) for female police officer fraction computation. \n",
    "\n",
    "For the different analysis of our study, there are mandatory features that must appear in each dataset in order to be able to fulfill our analysis. These are listed before each section in this notebook. Remaining interesting features are let in the filtered datasets, for potential data description. \n",
    "Some extra effort was moreover given to find various state and cities accross the USA that differ geographically, and on their potential sexist bias. Indeed, sexism could differ from state to state (which is one of the research question of this work), hence the datasets are commented by an indication on whether the state is a priori sexist or not, following https://www.chicagotribune.com/nation-world/ct-america-most-sexist-places-20180821-story.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For set 1 : \n",
    "    - age, gender, race\n",
    "    - reason for search + search_person and search_vehicle\n",
    "    - contraband_found\n",
    "    \n",
    "    \n",
    "North Carolina : Charlotte, Greensboro and Raleigh - very sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# North Carolina \n",
    "df_charlotte = pd.read_csv('data_P4/yg821jf8611_nc_charlotte_2020_04_01.csv.zip', compression='zip')\n",
    "df_raleigh = pd.read_csv('data_P4/yg821jf8611_nc_raleigh_2020_04_01.csv.zip', compression='zip')\n",
    "df_greensboro = pd.read_csv('data_P4/yg821jf8611_nc_greensboro_2020_04_01.csv.zip', compression='zip')\n",
    "name = ['Charlotte','Raleigh','Greensboro']\n",
    "\n",
    "for idx,df in enumerate([df_charlotte, df_raleigh, df_greensboro]):\n",
    "    print('\\n For : '+str(name[idx]))\n",
    "    print(set(df.columns))\n",
    "    print('Dimensions of dataframe before filtering :'+str(df.shape))\n",
    "    \n",
    "    # filtering \n",
    "    df.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search'], inplace=True)\n",
    "    df.drop(df.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "    \n",
    "    print('Dimensions of dataframe after :'+str(df.shape))\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "San Diego (California) - not so sexist\n",
    "- without frisk information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sandiego = pd.read_csv('data_P4/without_frisk_performed/yg821jf8611_ca_san_diego_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For : San Diego')\n",
    "print(set(df_sandiego.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_sandiego.shape))\n",
    "#filtering\n",
    "df_sandiego.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search'], inplace=True)\n",
    "df_sandiego.drop(df_sandiego.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_sandiego.shape))\n",
    "print(df_sandiego.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Austin (TX) - very sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For : San Diego\n",
      "{'raw_vehicle_search_search_based_on', 'raw_vehicle_searched', 'raw_street_check_description', 'subject_race', 'vehicle_registration_state', 'vehicle_model', 'reason_for_stop', 'raw_person_search_search_discovered', 'subject_sex', 'contraband_drugs', 'search_conducted', 'search_vehicle', 'raw_person_search_search_based_on', 'officer_id_hash', 'raw_race_description', 'frisk_performed', 'raw_person_searched', 'raw_row_number', 'date', 'type', 'contraband_weapons', 'vehicle_year', 'vehicle_make', 'subject_age', 'raw_vehicle_search_search_discovered', 'search_basis', 'search_person', 'contraband_found', 'raw_ethnicity'}\n",
      "Dimensions of dataframe before filtering :(483255, 29)\n",
      "Dimensions of dataframe after :(15039, 9)\n",
      "     subject_age subject_race subject_sex contraband_found  frisk_performed  \\\n",
      "406         19.0        black        male             True            False   \n",
      "416         27.0        black        male            False             True   \n",
      "420         56.0     hispanic        male            False             True   \n",
      "449         39.0        white        male            False             True   \n",
      "686         21.0        black        male            False             True   \n",
      "\n",
      "     search_person  search_vehicle                           reason_for_stop  \\\n",
      "406           True            True               SUSPICIOUS PERSON / VEHICLE   \n",
      "416           True            True  VIOLATION OF TRANSPORTATION/VEHICLE LAWS   \n",
      "420           True            True               SUSPICIOUS PERSON / VEHICLE   \n",
      "449           True           False  VIOLATION OF TRANSPORTATION/VEHICLE LAWS   \n",
      "686           True            True  VIOLATION OF TRANSPORTATION/VEHICLE LAWS   \n",
      "\n",
      "    reason_for_search  \n",
      "406    PROBABLE CAUSE  \n",
      "416  FRISK FOR SAFETY  \n",
      "420  FRISK FOR SAFETY  \n",
      "449  FRISK FOR SAFETY  \n",
      "686  FRISK FOR SAFETY  \n"
     ]
    }
   ],
   "source": [
    "df_austin = pd.read_csv('data_P4/yg821jf8611_tx_austin_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For : San Diego')\n",
    "print(set(df_austin.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_austin.shape))\n",
    "#filtering\n",
    "df_austin.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'raw_person_search_search_based_on'], inplace=True)\n",
    "df_austin.drop(df_austin.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'raw_person_search_search_based_on', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_austin.shape))\n",
    "#formatting\n",
    "df_austin = df_austin.rename(columns={'raw_person_search_search_based_on': 'reason_for_search'})\n",
    "print(df_austin.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maryland - least sexist state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MD = pd.read_csv('data_P4/without_frisk_performed/yg821jf8611_md_statewide_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For : Maryland')\n",
    "print(set(df_MD.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_MD.shape))\n",
    "#filtering\n",
    "df_MD.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search'], inplace=True)\n",
    "df_MD.drop(df_MD.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_MD.shape))\n",
    "print(df_MD.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For set 2 :\n",
    "    - age, gender, race\n",
    "    - reason for stop + contraband found\n",
    "    - citation OR warning OR arrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "San Francisco (California) - not so sexist\n",
    "\n",
    "- without frisk information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanfrancisco = pd.read_csv('data_P4/without_frisk_performed/yg821jf8611_ca_san_francisco_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For San Francisco')\n",
    "print(set(df_sanfrancisco.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_sanfrancisco.shape))\n",
    "#filtering \n",
    "df_sanfrancisco.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'reason_for_stop'], inplace=True)\n",
    "df_sanfrancisco.drop(df_sanfrancisco.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_sanfrancisco.shape))\n",
    "print(df_sanfrancisco.head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nashville (Tennessee) - very sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nashville = pd.read_csv('data_P4/yg821jf8611_tn_nashville_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For Nashville (TN)')\n",
    "print(set(df_nashville.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_nashville.shape))\n",
    "#filtering \n",
    "df_nashville.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'reason_for_stop'], inplace=True)\n",
    "df_nashville.drop(df_nashville.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_nashville.shape))\n",
    "print(df_nashville.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Orleans (Lousiana) - sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neworleans = pd.read_csv('data_P4/yg821jf8611_la_new_orleans_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print('\\n For New Orleans (Louisiana)')\n",
    "print(set(df_neworleans.columns))\n",
    "print('Dimensions of dataframe before filtering :'+str(df_neworleans.shape))\n",
    "#filtering \n",
    "df_neworleans.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'reason_for_stop'], inplace=True)\n",
    "df_neworleans.drop(df_neworleans.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)\n",
    "print('Dimensions of dataframe after :'+str(df_neworleans.shape))\n",
    "print(df_neworleans.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the case study : \n",
    "\n",
    "Florida state - sexist\n",
    "- no information on contraband\n",
    "- officer's gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FL = pd.read_csv('data_P4/yg821jf8611_fl_statewide_2020_04_01.csv.zip', compression='zip')\n",
    "\n",
    "print(set(df_FL.columns))\n",
    "print('Dimensions of dataframe :'+str(df_FL.shape))\n",
    "                            \n",
    "print('Male officers :'+format(len(df_FL[df_FL['officer_sex']=='male'])))\n",
    "print('Female officers :'+format(len(df_FL[df_FL['officer_sex']=='female'])))\n",
    "print('Fraction of women officers stop record before filtering : '+str(326525/4352689))\n",
    "\n",
    "# filtering\n",
    "df_FL.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'officer_sex', 'violation', 'reason_for_stop'], inplace=True)\n",
    "df_FL.drop(df_FL.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'violation', 'officer_sex', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other available datasets : \n",
    "\n",
    "Washington state - middle sexist\n",
    " - contains officer's gender \n",
    " - does not contain reason for search nor stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Washington state - middle\n",
    "df_WA = pd.read_csv('data_P4/yg821jf8611_wa_statewide_2020_04_01.csv.zip', compression='zip')\n",
    "# contains officers' gender\n",
    "\n",
    "print(set(df_WA.columns))\n",
    "print('Male officers :'+format(len(df_WA[df_WA['officer_sex']=='male'])))\n",
    "print('Female officers :'+format(len(df_WA[df_WA['officer_sex']=='female'])))\n",
    "print('Dimensions of dataframe :'+str(df_WA.shape))\n",
    "df_WA.dropna(subset=['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_conducted'], inplace=True)\n",
    "df_WA.drop(df_WA.columns.difference(['subject_age', 'subject_race', 'subject_sex', 'contraband_found', 'search_person', 'search_vehicle', 'reason_for_search', 'citation_issued','warning_issued','arrest_made', 'frisk_performed', 'reason_for_frisk', 'reason_for_stop', 'officer_sex' ]), 1, inplace = True)\n",
    "                                     \n",
    "print('Male officers :'+format(len(df_WA[df_WA['officer_sex']=='male'])))\n",
    "print('Female officers :'+format(len(df_WA[df_WA['officer_sex']=='female'])))\n",
    "print('Dimensions of dataframe :'+str(df_WA.shape))\n",
    "print('Fraction of women officers stop record before filtering : '+str(721258/10612167)+' fraction after : '+str(13757/225840))\n",
    "df_WA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are loaded just to show how few female police officer there are : between 4 and 9% of the stop were done by women, based on calculations for Louisville (KY), Pittsburgh (Philadelphia), Washington (state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Louisville, KY : sexist \n",
    "df_louisville = pd.read_csv('data_P4/yg821jf8611_ky_louisville_2020_04_01.csv.zip', compression='zip')\n",
    "print(set(df_louisville.columns))\n",
    "print('Dimensions of dataframe :'+str(df_louisville.shape))\n",
    "\n",
    "print('Male officers :'+format(len(df_louisville[df_louisville['officer_sex']=='male'])))\n",
    "print('Female officers :'+format(len(df_louisville[df_louisville['officer_sex']=='female'])))\n",
    "\n",
    "print('Fraction of women officers stop record before filtering : '+str(4870/105934))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pittsburgh, Philadelphia : middle \n",
    "df_PA_P = pd.read_csv('data_P4/yg821jf8611_pa_pittsburgh_2020_04_01.csv.zip', compression='zip')\n",
    "print(set(df_PA_P.columns))\n",
    "print('Dimensions of dataframe :'+str(df_PA_P.shape))\n",
    "                            \n",
    "print('Male officers :'+format(len(df_PA_P[df_PA_P['officer_sex']=='male'])))\n",
    "print('Female officers :'+format(len(df_PA_P[df_PA_P['officer_sex']=='female'])))\n",
    "\n",
    "print('Fraction of women officers stop record before filtering : '+str(16503/197809))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the filtered datasets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = [df_charlotte, df_raleigh, df_greensboro, df_austin, df_neworleans, df_sandiego, df_sanfrancisco, df_nashville, df_WA, df_MD, df_FL]\n",
    "name = ['df_charlotte', 'df_raleigh', 'df_greensboro', 'df_austin', 'df_neworleans', 'df_sandiego', 'df_sanfrancisco', 'df_nashville', 'df_WA', 'df_MD', 'df_FL']\n",
    "\n",
    "for idx,df in enumerate(DF):\n",
    "    df.to_csv('data_P4/'+name[idx]+'.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 1 : Gender disparities in search decisions\n",
    "\n",
    "The aim of this first part is to compare for W-M pairs the difference in search decision. The following method is applied :\n",
    "-  compare only individuals presenting similar subjective signals (except gender) to the police officer. For this, the following features are taken into account : \n",
    "     - match only person of same race\n",
    "     - match only person of different gender\n",
    "     - match only person with the same age range : this one is subjectively determined by assuming that only female under 45 could be attractive enough to generate a significant difference in decision outcome  \n",
    "     - match only person with the same behaviour during the traffic stop (feature : 'reason_for_search') \n",
    "- Compute difference in search (potentially also frisk) decision + confidence intervals\n",
    "- Fisher exact test to assess if the hit rates are significantly different between W and M. If the difference is not significant, it is no warranted to search a gender more than the other, so the difference in search decision is not justified and we conclude that there is gender discrimination.\n",
    "\n",
    "Citation and arrest are considered as severe outcome deicisons (1), whereas warning is considered as less severe (0). There is a difference between a person's search and a frisk : the former is more intrusive than the latter (see https://www.carrolltrobermanlaw.com/blog/2018/september/whats-the-difference-between-a-search-and-a-fris/). \n",
    "\n",
    "\n",
    "If available, the following information are provided in each dataframe :\n",
    "\n",
    "    'subject_age'\n",
    "    'subject_race'\n",
    "    'subject_sex'\n",
    "    'contraband_found'\n",
    "    'search_person'\n",
    "    'search_vehicle'\n",
    "    'reason_for_search'\n",
    "    'citation_issued'\n",
    "    'warning_issued'\n",
    "    'arrest_made'\n",
    "    'frisk_performed'\n",
    "    'reason_for_frisk'\n",
    "    'reason_for_stop'\n",
    "    'officer_sex' (only for WA, FL and Louisville)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic functions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DF_handling(df):\n",
    "    # create a index column\n",
    "    df['id']= df.index\n",
    "    \n",
    "    # Age category (proxy for attractiveness)\n",
    "    df['attractiveness'] = df.apply(lambda x: True if (x.subject_age<46) else False, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def match_pairs(df, reason_searches):\n",
    "    # match pairs on race, age range, contraband found (1:yes or 0:no), and search reason\n",
    "    matching=pd.DataFrame({'men':[],'women':[]})\n",
    "    AOD = 0\n",
    "    # Match 1 woman and 1 man with same attributes\n",
    "    for reason in reason_searches:\n",
    "        for race in ('white','black','hispanic'):\n",
    "            for attractiveness in ('True', 'False'):\n",
    "                for contraband in ('True', 'False'):\n",
    "                    for s_vehicle in ('True', 'False'):\n",
    "                        query = \"reason_for_search=='\"+reason+\"' & search_vehicle==\"+s_vehicle+\" & subject_race=='\"+race+\"' & attractiveness==\"+attractiveness+\" & contraband_found==\"+contraband\n",
    "                        data = df.query(query).copy()\n",
    "                        id_M = np.array(data[data['subject_sex']=='male'].id)\n",
    "                        id_W = np.array(data[data['subject_sex']=='female'].id)\n",
    "                        if ((len(id_M)>0) & (len(id_W)>0)):\n",
    "                            if (len(id_M)>len(id_W)):\n",
    "                                for i in np.arange(0,len(id_W)):\n",
    "                                    matching = matching.append({'men':id_M[i],'women':id_W[i]},ignore_index=True)\n",
    "                              \n",
    "                            if (len(id_M)<len(id_W)):\n",
    "                                for i in np.arange(0,len(id_M)):\n",
    "                                    matching = matching.append({'men':id_M[i],'women':id_W[i]},ignore_index=True)\n",
    "    return matching\n",
    "\n",
    "def AOD_s(df, matching):\n",
    "    # Averaged outcome difference (AOD) in search decision s \n",
    "    N_matches = len(matching)\n",
    "    diff = np.zeros(N_matches)\n",
    "\n",
    "    for i in np.arange(0,N_matches):\n",
    "        s_man = int(np.array(df[df['id']==matching.loc[i,'men']].search_person))\n",
    "        s_woman = int(np.array(df[df['id']==matching.loc[i,'women']].search_person))\n",
    "        diff[i] = s_man-s_woman                    \n",
    "    AOD = diff.sum()/N_matches    \n",
    "    \n",
    "    return AOD, diff\n",
    "\n",
    "def bootstrap_CI(data, nbr_draws):\n",
    "    # Confidence interval\n",
    "    # Bootstrap CI function from exercise session 2\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "\n",
    "    return [np.nanpercentile(means, 5),np.nanpercentile(means, 95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state(df, n):\n",
    "    # - compute the reason distribution in order to determine n, the number of reasons that are kept for the analysis.\n",
    "    # - match the pairs, compute AOD and interval of confidence\n",
    "    \n",
    "    df = DF_handling(df)\n",
    "\n",
    "    # Feature analysis : reason for search\n",
    "    Counter(df['reason_for_search'])\n",
    "\n",
    "    # Plot of the possible combination of the reason for search\n",
    "    plt.figure(figsize=[18,8])\n",
    "    plt.bar(Counter(df.dropna(subset=['reason_for_search']).reason_for_search).keys(), Counter(df.dropna(subset=['reason_for_search']).reason_for_search).values())\n",
    "\n",
    "    print('There are %d combinations of reasons for the policeman to decide to operate a search, among which, the most represented combinations are (in descending order of importance) :' %len(Counter(df['reason_for_search']).items()))\n",
    "    print(list(sorted(Counter(df.dropna(subset=['reason_for_search']).reason_for_search).items(), key=lambda x:x[1],  reverse=True))[:13])\n",
    "\n",
    "    # Possible reasons for search : n combinations chosen\n",
    "    reason_searches = sorted(Counter(df['reason_for_search']), key=Counter(df['reason_for_search']).get, reverse = True)[:n]\n",
    "    \n",
    "    matching = match_pairs(df, reason_searches)\n",
    "\n",
    "    [AOD, diff] = AOD_s(df, matching)\n",
    "\n",
    "    CI = bootstrap_CI(diff, 1000)\n",
    "\n",
    "    print('Averaged outcome difference %.4f with [%.4f, %.4f] 95%% confidence intervals' %(AOD, CI[0], CI[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the AOD and interval of confidence for each desired state or city\n",
    "state(df_charlotte, n=3)\n",
    "state(df_greensboro, n=4)\n",
    "state(df_raleigh, n=3)\n",
    "state(df_MD, n=3)\n",
    "state(df_sandiego, n=4)\n",
    "state(df_austin, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 2 : Gender disparities in stop outcome decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study : Gender disparities in Florida state policing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting\n",
    "df_FL['id']=df_FL.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
